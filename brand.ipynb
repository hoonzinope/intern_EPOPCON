{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from pyhive import presto\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from joblib  import Parallel, delayed\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm,tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> sql engine connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_engine = create_engine(\"mysql+pymysql://eums:eums00!q@192.168.0.118:3306/eums-poi?charset=utf8mb4\", encoding = 'utf8' ,\n",
    "                   pool_size=20,pool_recycle=3600,connect_args={'connect_timeout':1000000} )\n",
    "engine_presto = presto.connect('133.186.168.10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 상점 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "query = \"\"\"\n",
    "select ID,CO_NAME_R,CO_NAME\n",
    "from MEUMS_COMPANY\n",
    "\"\"\"\n",
    "#모든 상점 이름들 load\n",
    "company_name = pd.read_sql_query(query, company_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 지점 리스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select *\n",
    "from brand\n",
    "\"\"\"\n",
    "#단어별 등장 빈도수 저장된 table load\n",
    "brand = pd.read_sql_query(query, company_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "#~점 으로 끝나는 모든 단어 추출\n",
    "# 지점명을 거르기 위해\n",
    "for name in brand.CO_NAME.unique():\n",
    "    if '점' in name:\n",
    "        if '롯데' in name:\n",
    "            continue\n",
    "        if '신세계' in name:\n",
    "            continue\n",
    "        if '전문' in name:\n",
    "            continue\n",
    "        if '반점' in name:\n",
    "            continue\n",
    "        if '식당' in name:\n",
    "            continue\n",
    "        if '닭' in name:\n",
    "            continue\n",
    "        if '정육' in name:\n",
    "            continue\n",
    "        if '중화' in name:\n",
    "            continue\n",
    "        if 'BBQ' in name:\n",
    "            continue\n",
    "        if '숯' in name:\n",
    "            continue\n",
    "        if '보쌈' in name:\n",
    "            continue\n",
    "        if '삼겹살' in name:\n",
    "            continue\n",
    "        if '찌개' in name:\n",
    "            continue\n",
    "        if '밥' in name:\n",
    "            continue\n",
    "        if '피자' in name:\n",
    "            continue\n",
    "        if '만두' in name:\n",
    "            continue\n",
    "        if '순대' in name:\n",
    "            continue\n",
    "        if '족발' in name:\n",
    "            continue\n",
    "        if '고기' in name:\n",
    "            continue\n",
    "        if '갈비' in name:\n",
    "            continue\n",
    "        if '떡' in name:\n",
    "            continue\n",
    "        if '푸드' in name:\n",
    "            continue\n",
    "        if '축산' in name:\n",
    "            continue\n",
    "        if '주차' in name:\n",
    "            continue\n",
    "        if '치킨' in name:\n",
    "            continue\n",
    "        if '찜' in name:\n",
    "            continue\n",
    "        if '탕' in name:\n",
    "            continue\n",
    "        if '돼지' in name:\n",
    "            continue\n",
    "        if '뼈' in name:\n",
    "            continue\n",
    "        if '솥' in name:\n",
    "            continue\n",
    "        li.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_info = li\n",
    "location_info = set(location_info)\n",
    "location_info.remove('점')\n",
    "location_info.remove('원점')\n",
    "location_info.remove('호점')\n",
    "location_info.remove('시점')\n",
    "location_info.remove('지점')\n",
    "location_info.remove('공원점')\n",
    "location_info.remove('갈점')\n",
    "location_info.remove('1점')\n",
    "location_info.remove('화점')\n",
    "location_info.remove('소점')\n",
    "location_info.remove('매점')\n",
    "location_info.remove('호텔점')\n",
    "location_info.remove('마을점')\n",
    "location_info = sorted(list(location_info), key = len, reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 지점 리스트들로 브랜드 후보 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brand_dict_create(loaction_info,name):\n",
    "    random_store = {}\n",
    "    for l in location_info:\n",
    "        if l in name:\n",
    "            try:\n",
    "                random_store[name.replace(l,'')] += [name]\n",
    "            except:\n",
    "                random_store.update({name.replace(l,'') : [name]})\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    return random_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name_list = company_name.CO_NAME_R.unique()\n",
    "random_store_dict_list = Parallel(n_jobs = 6)(delayed(brand_dict_create)(location_info, company_name) for company_name in tqdm_notebook(company_name_list))\n",
    "\n",
    "random_store = {}\n",
    "for random_store_dict in random_store_dict_list:\n",
    "    for key in random_store_dict.keys():\n",
    "        value = set(random_store_dict[key])\n",
    "        try:\n",
    "            random_store[key].update(value)\n",
    "        except:\n",
    "            random_store.update({key:value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> re-filtering <br> 지점리스트(location_info)에 상점명이 통째로 들어가 있는 경우 <br>\n",
    "detect 하지 못하기 때문에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_name_list = random_store['']\n",
    "location_info = sorted(list(location_info), key = len)\n",
    "for co_name in ex_name_list:\n",
    "    for l in location_info:\n",
    "        if l in co_name:\n",
    "            try:\n",
    "                random_store[co_name.replace(l,'')].add(co_name)\n",
    "            except:\n",
    "                random_store.update({co_name.replace(l,'') : {co_name}})\n",
    "            break\n",
    "del random_store['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_candidate = pd.DataFrame(pd.Series(ra)).reset_index()\n",
    "brand_candidate.to_pickle('brand_candidate_dict.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> document 유사도 비교 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(text_list, location_info):\n",
    "    location = set(location_info)\n",
    "    location.add('')\n",
    "    location.add(' ')\n",
    "    location.add('스타샵')\n",
    "    location.add('주')\n",
    "    location.add('주식회사')\n",
    "    location.add('유')\n",
    "    location.add('유한회사')\n",
    "    location.add('더')\n",
    "    location.add('null')\n",
    "    location.add('*')\n",
    "    porter = nltk.PorterStemmer()\n",
    "    stemmed_tokens= []\n",
    "    for texts in text_list:\n",
    "        for text in texts:\n",
    "            stemmed_tokens += [porter.stem(t) for t in re.split('[( )]+',text) if t not in location and len(t) != 1 and '*' not in t]\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [w for w in stemmed_tokens]\n",
    "    count = nltk.defaultdict(int)\n",
    "    for word in filtered_tokens:\n",
    "        count[word] += 1\n",
    "    return count\n",
    "\n",
    "#req_co_name을 단어별로 count 해주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a,b):\n",
    "    dot_product = np.dot(a,b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    if (norm_a * norm_b) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return dot_product / (norm_a * norm_b)\n",
    "    \n",
    "#cosine 유사도 공식 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimilarity(dict1 , dict2):\n",
    "    all_words_list = []\n",
    "    for key in dict1:\n",
    "        all_words_list.append(key)\n",
    "    for key in dict2:\n",
    "        all_words_list.append(key)\n",
    "    all_words_list_size = len(all_words_list)\n",
    "    \n",
    "    v1 = np.zeros(all_words_list_size, dtype = np.int)\n",
    "    v2 = np.zeros(all_words_list_size, dtype = np.int)\n",
    "    \n",
    "    i = 0\n",
    "    for (key) in all_words_list:\n",
    "        v1[i] = dict1.get(key, 0)\n",
    "        v2[i] = dict2.get(key, 0)\n",
    "        i = i+1\n",
    "    return cos_sim(v1,v2)\n",
    "\n",
    "#cosine 유사도를 통해 req_co_name_document 간 유사도를 계산합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> document 생성을 위한 id_list 생성 <br>\n",
    "document 생성을 위한 req_co_name_list 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_co_name_create(id_list):\n",
    "    id_list = [int(n)for n in id_list]\n",
    "    ITEM_PART= [n % 100 for n in id_list]\n",
    "    dic = {}\n",
    "\n",
    "    for item_part, id in zip(ITEM_PART, id_list):\n",
    "        if not item_part in dic:\n",
    "            dic[item_part] = [id]\n",
    "        else:\n",
    "            dic[item_part].append(id) \n",
    "        \n",
    "    engine_presto = presto.connect('133.186.168.10')\n",
    "    req_name = []\n",
    "    for key in dic.keys():\n",
    "        id_part = key\n",
    "        co_id = tuple([str(number) for number in dic[key]])\n",
    "        if len(co_id) > 1:\n",
    "            query = \"\"\"\n",
    "            select *\n",
    "            from meums_comp_req_mapp_comp\n",
    "            where id_part = {} and co_id in {}\n",
    "            \"\"\".format(id_part, co_id)\n",
    "\n",
    "            req_name += list(pd.read_sql_query(query, engine_presto).req_co_name.values)\n",
    "        else:\n",
    "            co_id = \"'\"+str(dic[key][0])+\"'\"\n",
    "            query = \"\"\"\n",
    "            select *\n",
    "            from meums_comp_req_mapp_comp\n",
    "            where id_part = {} and co_id = {}\n",
    "            \"\"\".format(id_part, co_id)\n",
    "            req_name += list(pd.read_sql_query(query, engine_presto).req_co_name.values)\n",
    "    return [req_name]\n",
    "\n",
    "#req_co_name document 를 생성하기 위한 함수\n",
    "#partitioning 된 table 접근 -> 속도 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id_list(company_list):\n",
    "    id_list = []\n",
    "    for co_name_r in company_list:\n",
    "        id_list.append(str(company_name[company_name.CO_NAME_R == co_name_r].ID.values[0]))\n",
    "    return id_list\n",
    "\n",
    "#실제 상점의 id_list를 생성하기 위한 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>브랜드 후보 마다 상점명의 문자정보 document 생성 <br>\n",
    "생성된 document 유사도 비교 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "count = 0\n",
    "co_name_list = []\n",
    "req_co_name_list = []\n",
    "for key in random_store.keys():\n",
    "    if len(random_store[key]) > 3: #점포가 3개 이상인 상점들에 대해서만 계산 수행\n",
    "        co_name_list += [key]\n",
    "        req_co_name_list += [list(random_store[key])]\n",
    "print('co_name_list create', len(co_name_list))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('ID_LIST_create...')\n",
    "id_list_list = [] #점포가 3개이상인 상점들의 실제 상점들 ID list 생성\n",
    "id_list_list = (Parallel(n_jobs = 6)(delayed(create_id_list)(company_list) for company_list in tqdm_notebook(req_co_name_list)))\n",
    "print('ID_LIST_create success!', len(id_list_list))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('req_co_name_list create...')#위 생성 list를 이용해 req_co_name을 들고 옵니다. 각 브랜드별 문자정보 document 생성\n",
    "documents = Parallel(n_jobs = 8)(delayed(req_co_name_create)(id_list) for id_list in tqdm_notebook(id_list_list))\n",
    "print('req_co_name_list create success!')\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('dict_list_create...') #document 간 계산을 위한 단어 별 단어빈도수 dictionary 생성\n",
    "dicts_list = Parallel(n_jobs = -1)(delayed(process)(document,location_info) for document in tqdm_notebook(documents))\n",
    "print('dicts_list create success!')\n",
    "print('\\n')\n",
    "\n",
    "#document 간 유사도 matrix 생성\n",
    "print('similarity matrix create...')\n",
    "result = []\n",
    "for criteria_dict in tqdm_notebook(dicts_list):\n",
    "    r = []\n",
    "    for compare_dict in dicts_list:\n",
    "        r += [getSimilarity(criteria_dict,compare_dict) * 100]\n",
    "    result += [r]\n",
    "\n",
    "final_result = pd.DataFrame(result , index = co_name_list, columns = co_name_list)\n",
    "print('similarity matrix create success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result.to_pickle('brand_list_similarity.pkl') #중간결과 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 덜 묶인 brand 끼리 union binding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = {}\n",
    "for name in final_result.columns:\n",
    "    similar_name = final_result[name].sort_values(ascending = False).iloc[1:2].index[0]\n",
    "    if final_result[name].sort_values(ascending = False).iloc[1:2].values > 5:\n",
    "        try:\n",
    "            if len(name) < len(similar_name):\n",
    "                g[name].update({similar_name})\n",
    "            else:\n",
    "                g[similar_name].update({name})\n",
    "        except:\n",
    "            if len(name) < len(similar_name):\n",
    "                g.update({name : {similar_name}})\n",
    "            else:\n",
    "                g.update({similar_name : {name}})\n",
    "print('calculate done')  \n",
    "\n",
    "jump_id = set([])\n",
    "remove_list = []\n",
    "for name in g.keys():\n",
    "    if len(jump_id) > 0:\n",
    "        if name in jump_id:\n",
    "            remove_list.append(name)\n",
    "            continue\n",
    "    try:\n",
    "        if name in g[list(g[name])[0]]:\n",
    "            jump_id.update(g[name])\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "for key in remove_list:\n",
    "    del g[key]\n",
    "print('reference each other set remove done')\n",
    "\n",
    "# remove_list = []\n",
    "for key_1 in g.keys():\n",
    "    for key_2 in g.keys():\n",
    "        if key_2 in g[key_1]:\n",
    "            g[key_1].update(g[key_2])\n",
    "#             remove_list.append(key_2)\n",
    "print('union binding 1st done')\n",
    "\n",
    "# for re_name in set(remove_list):\n",
    "#     del g[re_name]\n",
    "# print('remove useless union done')\n",
    "\n",
    "remove_list = []\n",
    "for key_1 in g.keys():\n",
    "    for key_2 in g.keys():\n",
    "        if key_1 != key_2:\n",
    "            if g[key_1] & g[key_2]:\n",
    "                if len(key_1) < len(key_2):\n",
    "                    g[key_1].update(g[key_2])\n",
    "                    g[key_1].add(key_2)\n",
    "                    remove_list.append(key_2)\n",
    "                    break\n",
    "                else:\n",
    "                    g[key_2].update(g[key_1])\n",
    "                    g[key_2].add(key_1)\n",
    "                    remove_list.append(key_1)\n",
    "                    break              \n",
    "for re_name in set(remove_list):\n",
    "    del g[re_name]\n",
    "    \n",
    "print('union binding 2st done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 브랜드-상점 mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_brand_company_mapping_dict = {}\n",
    "for key_brand in g.keys():\n",
    "    sub_brand = g[key_brand]\n",
    "    sub_brand.add(key_brand)\n",
    "    mapping_company = []\n",
    "    for brand in sub_brand:\n",
    "        count = 0\n",
    "        for name in final_result.columns:\n",
    "            if name == brand:\n",
    "                break\n",
    "            count += 1\n",
    "        mapping_company += id_list_list[count]\n",
    "    result_brand_company_mapping_dict.update({key_brand : tuple(mapping_company)})\n",
    "\n",
    "#브랜드와 상점을 매핑하기 위해서 위에서 사용했던 id_list_list를 활용\n",
    "#상위 브랜드로 묶인 실제 상점들과\n",
    "\n",
    "#관련이 없어서 묶이지 않은 브랜드의 실 상점들을 id_list_list를 이용해\n",
    "#브랜드 = 상점_id로 구상된 dictionary 생성\n",
    "temp_set = set([])\n",
    "for key in g.keys():\n",
    "    temp_set.update(g[key])\n",
    "    temp_set.add(key)\n",
    "for key_brand in final_result.columns:\n",
    "    if key_brand not in temp_set:\n",
    "        mapping_company = []\n",
    "        count = 0\n",
    "        for name in final_result.columns:\n",
    "            if name == key_brand:\n",
    "                break\n",
    "            count += 1\n",
    "        mapping_company += id_list_list[count]\n",
    "        result_brand_company_mapping_dict.update({key_brand : tuple(mapping_company)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ = pd.DataFrame(pd.Series(result_brand_company_mapping_dict)).reset_index()\n",
    "temp_.columns = ['brand','co_id']\n",
    "temp_.to_pickle('final_brand_result.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> company(지금은 임시 table = TEMP0001) table에 brand, modify 여부 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#위에서 나온 결과로 company table에 새 칼럼(brand, modify) 추가\n",
    "for brand in tqdm_notebook(temp_.brand):\n",
    "    co_id = temp_[temp_.brand == brand].co_id.values[0]\n",
    "    query =\"\"\"\n",
    "    update TEMP0001\n",
    "      set BRAND = '{}', \n",
    "          modify = 1\n",
    "      where ID in {}\n",
    "    \"\"\".format(brand, co_id)\n",
    "    try:\n",
    "        pd.read_sql_query(query, company_engine)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
